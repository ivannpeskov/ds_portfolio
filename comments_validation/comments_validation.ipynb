{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9d351f",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3884ad",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd02222",
   "metadata": {},
   "source": [
    "В рамках запуска нового сервиса сайта \"Викишоп\", позволяющего пользователям добавлять и редактировать описание товаров и услуг, необходимо разработать модель машинного обучения, которая будет определять тональность оставленного комментария и, в случае, если комментарий будет классифицирован, как негативный, отправлять его на дополнительную модерацию. Это позволит значительно разгрузить модераторов, которым необходимо будет валидировать только часть описаний. \n",
    "В нашем распоряжении ~ 150 000 тысяч комментариев с сайта викишоп, размеченные по уровню токсичности. \n",
    "\n",
    "**План работ:** \n",
    "\n",
    "1. Изучить данные. \n",
    "2. Лемматизировать тексты в корпусе. \n",
    "3. Выполнить токенизацию текстов корпуса, с оценкоц важности слов метрикой TF и IDF. \n",
    "4. Обучить модель машинного обчения и проверить ее на валидационной выборке. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eefafc6",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a19767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tqdm\n",
    "from tqdm import notebook\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d14343",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Желательно чтобы все импорты были собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b30a58",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Да, стараюсь собирать их в одном месте. Просто здесь как будто два проекта в одной тетрадке, поэтому импорты для Bert ниже. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8c093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df = df.drop(columns = 'Unnamed: 0')\n",
    "#df = df[0:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefaa0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1ceb5",
   "metadata": {},
   "source": [
    "Во всех колонках одинаковое количество строк, типы данных в колонках корректные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c61d97",
   "metadata": {},
   "source": [
    "## Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99a8bc",
   "metadata": {},
   "source": [
    "Создадим корпус текстов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af7077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170cc130",
   "metadata": {},
   "source": [
    "Выполним в цикле лемматизацию корпуса с заменой всех символов, отличных от латинского алфавита. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fd281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ba8b7781b342d39eae687de16cdefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "new_corpus = []\n",
    "for i in notebook.tqdm(range(corpus.shape[0])):\n",
    "    tokenized = nltk.word_tokenize(corpus[i])\n",
    "    lemma = ' '.join([wnl.lemmatize(x) for x in tokenized])\n",
    "    lemma = ' '.join(re.sub(r'[^a-zA-z]', ' ',lemma).split())\n",
    "    new_corpus.append(lemma)\n",
    "new_corpus = np.array(new_corpus).astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7cd45",
   "metadata": {},
   "source": [
    "Лемматизация тестов выполнена. \n",
    "\n",
    "Создадим вектор для каждого текста с помощью метрик TF, IDF. \n",
    "\n",
    "Также учтем стоп-слова при оценке важности слов корпуса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9759b6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны правильно, молодец!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ddaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(new_corpus, target, test_size=0.1, random_state=12345)\n",
    "print (features_train.shape)\n",
    "print (features_valid.shape)\n",
    "print (target_train.shape)\n",
    "print (target_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1112c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "tf_idf_vect = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf_train = tf_idf_vect.fit_transform(features_train)\n",
    "tf_idf_valid = tf_idf_vect.transform(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a391fc",
   "metadata": {},
   "source": [
    "Данные готовы для обучения модели. В качестве метрики будем использовать f1. Рассчет метрики осуществим с помощью кросс валидации. \n",
    "\n",
    "В качестве классификатора будем использовать CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b69ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано верно. Отлично, что векторизатор был обучен только на тренировочной части данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472f7f6",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73be944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=4,\n",
    "                           depth=5,\n",
    "                           learning_rate=0.7,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "model.fit(tf_idf_train, target_train)\n",
    "scores = cross_val_score(model, tf_idf_train, target_train, cv=5, scoring = 'f1')\n",
    "np.median(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d79c8c",
   "metadata": {},
   "source": [
    "Также, попробуем обучить и оценить метрикой f1 с помощью кросс-валидации логистическую регрессию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, max_iter=1200, class_weight='balanced', solver = 'lbfgs')\n",
    "model.fit(tf_idf_train, target_train)\n",
    "scores = cross_val_score(model, tf_idf_train, target_train, cv=5, scoring = 'f1')\n",
    "np.median(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e64bdc",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57772e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(tf_idf_valid)\n",
    "score = round(f1_score(target_valid, predictions),2)\n",
    "print ('метрика f1 составляет', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabc744",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f4fe2",
   "metadata": {},
   "source": [
    "Для разработки модели анализа комментариев пользователей сайта \"Викишоп\" был использован корпус комментариев, размеченный по уровню негативности в размере 159 000 штук. \n",
    "\n",
    "Все тексты были лемматизированы, и токенизированы в рамках подготовки к обучению. \n",
    "В качестве моделей были выбраны Логистическая регрессия и catBoost. В качестве метрики качества была использована метрика f1. \n",
    "\n",
    "На валидационной выборке выбранная и обученная модель логистической регрессии метрика составила 0,75. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba0258",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Тестирование было сделано правильно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100bf68",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп». BERT.  Факультативно.\n",
    "#### Если возможно, прошу тажке оставить комментарии по реализации с BERT (у меня не получилось прогнать скрипты на полных данных, так как прогресс бар показывал 52 часа на создание эмбедингов, но интересно, насколько реализация близка к правде) Спасибо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd66b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3468e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30a040",
   "metadata": {},
   "source": [
    "Удаляю тексты, длиной более 512, так как модель не работает с текстами бОльшей длины. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab581099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[0:400]\n",
    "df = df.drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(index = df[df['text'].apply(lambda x: len(x))>512].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb286c2f",
   "metadata": {},
   "source": [
    "Токенизируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562eadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer(vocab_file='vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook.tqdm.pandas()\n",
    "tokenized = df['text'].progress_apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b590201",
   "metadata": {},
   "source": [
    "Проверим максимальную длину. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0 \n",
    "for i in range(len(tokenized)):\n",
    "    if len(tokenized[i])>max_len:\n",
    "        max_len = len(tokenized[i])\n",
    "        max_len_token = i\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e06a55",
   "metadata": {},
   "source": [
    "Уравняем длины полчившихся, после токенизации векторов. \n",
    "Также, удалим лишние нули из векторов, сохраняя единую длину. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b98cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = []\n",
    "for i in range(len(tokenized)):\n",
    "    padded_i = tokenized[i] + [0]*(max_len-len(tokenized[i]))\n",
    "    padded.append(padded_i)\n",
    "padded = np.array(padded)\n",
    "attention_mask = np.where(padded!=0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17420175",
   "metadata": {},
   "source": [
    "Создадим эмбединги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_json_file('bert_config.json')\n",
    "model = transformers.BertModel.from_pretrained('pytorch_model.bin', config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embendings = []\n",
    "batch_size = 100\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0]//batch_size + 1)):\n",
    "    batch = torch.LongTensor(padded[i*batch_size:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embendings = model(batch, attention_mask = attention_mask_batch)\n",
    "    \n",
    "    embendings.append(batch_embendings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9f248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embendings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52e193",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, \n",
    "                                                                              test_size=0.2, \n",
    "                                                                              random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "model.fit(features_train, target_train)\n",
    "scores = cross_val_score(model, features_train, target_train, cv = 5, scoring='f1')\n",
    "np.median(np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccbf57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, max_iter=1200)\n",
    "model.fit(features_train, target_train)\n",
    "scores = cross_val_score(model, features_train, target_train, cv = 5, scoring='f1')\n",
    "np.median(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e5768a",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd492c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(features_valid)\n",
    "score = round(f1_score(target_valid, predictions),2)\n",
    "print ('метрика f1 составляет', score)"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2438,
    "start_time": "2022-10-18T05:05:16.318Z"
   },
   {
    "duration": 3425,
    "start_time": "2022-10-18T05:05:18.758Z"
   },
   {
    "duration": 33,
    "start_time": "2022-10-18T05:05:22.185Z"
   },
   {
    "duration": 20,
    "start_time": "2022-10-18T05:05:22.221Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
